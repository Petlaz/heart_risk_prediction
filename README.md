# Heart Risk Prediction with Explainable AI

## Project Overview

This project develops an interpretable machine learning system for predicting heart disease risk using comprehensive health, demographic, and lifestyle data from the European Social Survey. The system integrates high-performance prediction models with explainable AI (XAI) techniques to provide clinically relevant insights through a production-ready web application.

**Status**: Production Complete - Full implementation with Docker deployment

## Key Features

- **Machine Learning Pipeline**: Complete baseline modeling, hyperparameter optimization, and performance evaluation across 5 algorithms
- **Explainable AI**: SHAP implementation with clinical feature importance analysis and root cause investigation
- **Web Application**: Professional Gradio-based interface with medical-grade styling and safety compliance
- **Production Deployment**: Docker containerization with both local and public URL capabilities
- **Comprehensive Documentation**: 58-reference literature review, academic reports, and technical documentation
- **Clinical Integration**: Healthcare-focused evaluation metrics, safety analysis, and decision support frameworks

## Research Achievements

### Model Performance Analysis
- **Best Model**: Adaptive_Ensemble (F1-Score: 0.175, Sensitivity: 14.3%, Specificity: 98.4%)
- **Clinical Assessment**: All models fail clinical deployment criteria (â‰¥80% sensitivity required)
- **Literature Comparison**: Significant gap vs. published benchmarks (0.65-0.92 F1) reveals methodological challenges
- **Medical Risk**: 822 missed heart disease cases per 8,476 patients represents unacceptable clinical risk

### Explainable AI Insights
- **SHAP Analysis**: BMI (0.0208), Physical Activity (0.0189), and Mental Effort (0.0149) identified as top predictors
- **Root Cause**: Missing traditional cardiac risk factors (ECG, chest pain, family history) limits predictive capability
- **Optimization Paradox**: Weak psychological predictors cannot be optimized for clinical-grade performance
- **Dataset Limitations**: Models attempt lifestyle survey prediction rather than medical diagnosis

### Clinical Implications
- **Feature Quality**: Dataset emphasizes happiness/mood variables lacking cardiac predictive signal
- **Healthcare Standards**: Research demonstrates need for medical-specific evaluation criteria
- **Academic Contribution**: Provides methodology for honest assessment of healthcare ML deployment challenges

### Interactive Application Framework âœ… **COMPLETE**

**Professional Gradio Application Implementation:**
- **"Heart Disease Risk Prediction App"**: Medical-grade web interface
- **Model Integration**: Adaptive_Ensemble VotingClassifier with real-time predictions
- **Clinical Features**: 22-parameter health assessment system

### Production Deployment Infrastructure âœ… **COMPLETE**

**ğŸ³ Docker Containerization Achievement:**
- **Container Status**: docker-heart-risk-app-1 running successfully 
- **Port Configuration**: 0.0.0.0:7860->7860/tcp functional
- **Professional Startup**: Emoji-enhanced logging with system validation
- **Dependency Management**: Version-constrained requirements (Gradio 3.50.0-4.0.0)
- **Local URL**: http://localhost:7860 accessible and responding
- **Public URL**: Automatic generation with Gradio share=True capability
- **Medical Interface**: Professional medical-grade styling maintained in container
- **XAI Integration**: SHAP explanations functional in containerized environment

**Deployment Validation Results:**
```bash
ğŸ«€ Starting Heart Risk Prediction Application...
ğŸ“‹ Checking system requirements...
âœ… Processed data found
âœ… Trained models found
ğŸš€ Starting Professional Heart Disease Risk Prediction App...
ğŸ“± Local URL: http://0.0.0.0:7860
ğŸŒ Public URL: Will be generated automatically with share=True
ğŸ³ Docker deployment ready
```

**Production Features:**
- **Professional Logging**: Enhanced startup with emoji status indicators
- **System Validation**: Automatic data preprocessing and model detection
- **Clinical Safety**: Medical-grade interface compliance maintained
- **Research Accessibility**: Both local and public URL sharing for dissemination
- **Risk Stratification**: Three-tier classification (Low/Moderate/High Risk)
- **XAI Integration**: SHAP-informed feature importance analysis
- **Professional Compliance**: Medical disclaimers and safety guidance
- **Deployment Ready**: Docker containerization with local/public URL sharing

**Application URLs:**
- **Local Access**: http://localhost:7860
- **Public Sharing**: https://409bf8393229402985.gradio.live (7-day expiry)
- **Docker Deployment**: Port 7860 with complete containerization

**Clinical Implementation Results:**
- **Interface Quality**: Professional medical-grade styling and user experience
- **Prediction Performance**: Consistent with XAI analysis (77-78% high risk predictions)
- **Safety Standards**: Comprehensive medical disclaimers and professional consultation guidance
- **Deployment Validation**: Successfully tested local and public accessibility
- **Technical Achievement**: Complete integration of ML pipeline into user-friendly clinical interface

## Research Methodology

### Implementation Framework
1. **Hyperparameter Optimization**: RandomizedSearchCV with F1-score optimization and Apple Silicon efficiency
2. **Model Validation**: Test set validation revealing performance hierarchy and overfitting patterns
3. **Error Analysis**: Comprehensive post-optimization investigation with clinical safety assessment
4. **Literature Review**: 58 peer-reviewed references (2019-2026) with healthcare ML methodology analysis
5. **Explainable AI**: SHAP implementation for clinical feature importance and root cause analysis
6. **Production Deployment**: Professional Docker containerization with medical-grade interface

### Performance Results
| Model | Test F1-Score | Sensitivity | Specificity | Clinical Assessment |
|-------|---------------|-------------|-------------|---------------------|
| **Adaptive_Ensemble** | **0.175** | 14.3% | 98.4% | Best performance but clinically unsafe |
| Optimal_Hybrid | 0.091 | 5.4% | 99.1% | Extremely conservative, misses 94.6% cases |
| Adaptive_LR | 0.032 | 1.8% | 99.4% | Nearly unusable for screening |

### Key Findings
- **Clinical Safety Failure**: All models fail healthcare deployment criteria (required â‰¥80% sensitivity)
- **Performance Gap**: Significant disparity vs. published benchmarks (65-92% F1) indicates methodological challenges
- **Psychological Insufficiency**: Mental health variables inadequate for clinical-grade heart disease prediction
- **Economic Impact**: 822 missed cases per 8,476 patients represents unacceptable medical risk

## Project Structure

```
heart_risk_prediction/
â”œâ”€â”€ .gitignore                   # Git ignore patterns
â”œâ”€â”€ LICENSE                      # MIT License
â”œâ”€â”€ README.md                    # This file - project documentation âœ… **UPDATED**
â”œâ”€â”€ requirements.txt             # Host environment dependencies âœ… **ENHANCED**
â”œâ”€â”€ app/                         # Professional Web Application âœ… **COMPLETE**
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ app_gradio.py           # Heart Disease Risk Prediction App (Medical-grade interface)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ heart_data.csv      # European Social Survey health data
â”‚   â”œâ”€â”€ processed/               # Clean splits + artifacts âœ… **COMPLETE**
â”‚   â”‚   â”œâ”€â”€ feature_names.csv   # Feature mapping and descriptions
â”‚   â”‚   â”œâ”€â”€ health_clean.csv    # Preprocessed dataset
â”‚   â”‚   â”œâ”€â”€ test.csv            # Test set (stratified)
â”‚   â”‚   â”œâ”€â”€ train.csv           # Training set (stratified)
â”‚   â”‚   â””â”€â”€ validation.csv      # Validation set (stratified)
â”‚   â””â”€â”€ data_dictionary.md       # Feature documentation
â”œâ”€â”€ docker/                      # Production Containerization âœ… **COMPLETE**
â”‚   â”œâ”€â”€ Dockerfile               # Optimized container image with version constraints
â”‚   â”œâ”€â”€ docker-compose.yml       # Multi-service orchestration
â”‚   â”œâ”€â”€ entrypoint_app.sh        # Professional startup with emoji logging âœ… **NEW**
â”‚   â”œâ”€â”€ requirements_docker.txt  # Version-constrained dependencies âœ… **NEW**
â”‚   â””â”€â”€ README.md                # Complete Docker deployment guide âœ… **UPDATED**
â”œâ”€â”€ notebooks/                   # Research Pipeline âœ… **ALL COMPLETE**
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb # Data exploration and EDA âœ…
â”‚   â”œâ”€â”€ 02_data_processing.ipynb # Data preprocessing pipeline âœ…
â”‚   â”œâ”€â”€ 03_modeling.ipynb       # Model training and evaluation âœ…
â”‚   â”œâ”€â”€ 04_error_analysis.ipynb # Error analysis and diagnostics âœ…
â”‚   â””â”€â”€ 05_explainability.ipynb # XAI implementation with SHAP analysis âœ… **Complete**
â”œâ”€â”€ reports/                     # Comprehensive Documentation âœ… **ALL UPDATED**
â”‚   â”œâ”€â”€ biweekly_meeting_1.md   # Sprint 1-2 progress summary âœ…
â”‚   â”œâ”€â”€ biweekly_meeting_2.md   # Sprint 3-4 completion summary âœ…
â”‚   â”œâ”€â”€ biweekly_meeting_3.md   # Sprint 5-6 completion summary âœ…
â”‚   â”œâ”€â”€ biweekly_meeting_4.md   # Sprint 7-8 completion summary âœ… **COMPLETE**
â”‚   â”œâ”€â”€ biweekly_meeting_5.md   # Sprint 9-10 completion summary âœ… **COMPLETE**
â”‚   â”œâ”€â”€ biweekly_meeting_6.md   # Sprint 11-12 progress summary (Planning)
â”‚   â”œâ”€â”€ final_report.md         # Academic thesis/final report âœ… **ENHANCED**
â”‚   â”œâ”€â”€ literature_review.md    # Research background and related work âœ… **UPDATED**
â”‚   â””â”€â”€ project_plan_and_roadmap.md # Project timeline and milestones
â”œâ”€â”€ results/                     # Model Artifacts & Analysis âœ… **COMPLETE**
â”‚   â”œâ”€â”€ approach_comparison.csv  # Optimization comparison âœ…
â”‚   â”œâ”€â”€ comprehensive_model_metrics.csv # Detailed performance metrics âœ…
â”‚   â”œâ”€â”€ confusion_matrices/     # Model confusion matrix visualizations
â”‚   â”œâ”€â”€ explainability/         # XAI artifacts and visualizations âœ… **Week 5-6 Complete**
â”‚   â”‚   â”œâ”€â”€ shap_feature_importance.png # Global feature importance âœ…
â”‚   â”‚   â”œâ”€â”€ shap_summary_beeswarm.png   # Feature effects visualization âœ…
â”‚   â”‚   â”œâ”€â”€ shap_summary_detailed.png   # Comprehensive SHAP analysis âœ…
â”‚   â”‚   â”œâ”€â”€ shap_feature_importance_bar.png # Bar plot visualization âœ…
â”‚   â”‚   â””â”€â”€ clinical/           # Clinical decision support templates
â”‚   â”œâ”€â”€ explanations/           # Clinical explanation artifacts âœ…
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ clinical_decision_support_template.md
â”‚   â”‚   â””â”€â”€ clinical_risk_factor_analysis.csv
â”‚   â”œâ”€â”€ metrics/                # Performance metrics and diagnostics
â”‚   â”‚   â””â”€â”€ classification_reports/
â”‚   â”œâ”€â”€ models/                 # Trained model artifacts âœ… **Integrated Week 7-8**
â”‚   â”‚   â”œâ”€â”€ adaptive_tuning/    # Adaptive_Ensemble (Best performing, integrated in app)
â”‚   â”‚   â”œâ”€â”€ enhanced_techniques/ # Additional optimized models
â”‚   â”‚   â”œâ”€â”€ data_splits.joblib  # Train/validation/test splits
â”‚   â”‚   â””â”€â”€ standard_scaler.joblib # Fitted preprocessing scaler
â”‚   â””â”€â”€ plots/                  # Visualization outputs
â””â”€â”€ src/                        # Core Implementation âœ… **COMPLETE**
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.yaml             # Project configuration settings
    â”œâ”€â”€ data_preprocessing.py   # EDA + preprocessing pipeline âœ…
    â”œâ”€â”€ train_models.py         # Model training orchestration âœ…
    â”œâ”€â”€ evaluate_models.py      # Model evaluation framework âœ…
    â”œâ”€â”€ explainability.py       # XAI implementation â³
    â”œâ”€â”€ utils.py                # Shared utilities and helpers âœ…
    â”œâ”€â”€ models/                 # Model architectures
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ neural_network.py   # Neural network implementation âœ…
    â””â”€â”€ tuning/                 # Hyperparameter optimization âœ…
        â”œâ”€â”€ __init__.py
        â””â”€â”€ randomized_search.py # RandomizedSearchCV framework âœ…
```
â”‚   â”œâ”€â”€ confusion_matrices/     # Model confusion matrix visualizations
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â”œâ”€â”€ explainability/        # XAI artifacts and visualizations
â”‚   â”‚   â””â”€â”€ clinical/          # Clinical decision support templates
â”‚   â”œâ”€â”€ explanations/          # Local explanation artifacts
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ clinical_decision_support_template.md
â”‚   â”œâ”€â”€ metrics/               # Performance metrics and diagnostics
â”‚   â”‚   â””â”€â”€ classification_reports/
â”‚   â”œâ”€â”€ models/                # Trained model artifacts
â”‚   â””â”€â”€ plots/                 # Visualization outputs
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.yaml            # Project configuration settings
    â”œâ”€â”€ data_preprocessing.py  # EDA + preprocessing pipeline
    â”œâ”€â”€ train_models.py        # Model training orchestration
    â””â”€â”€ utils.py               # Shared utilities and helpers
```

## Usage

### Jupyter Notebooks - Research Pipeline

The analysis follows a systematic research methodology across 5 comprehensive notebooks:

1. **01_exploratory_analysis.ipynb**: âœ… **COMPLETE**
   - Initial data exploration and visualization
   - Statistical analysis and feature correlation assessment
   - Clinical relevance evaluation

2. **02_data_processing.ipynb**: âœ… **COMPLETE**
   - Data cleaning and validation
   - Feature engineering and selection
   - Train/validation/test splits with stratification

3. **03_modeling.ipynb**: âœ… **COMPLETE**
   - Baseline model implementation (5 algorithms)
   - Hyperparameter optimization (RandomizedSearchCV)
   - Test set validation and performance comparison

4. **04_error_analysis.ipynb**: âœ… **COMPLETE** 
   - Comprehensive post-optimization error investigation
   - Clinical safety assessment with deployment criteria
   - Cross-model error pattern analysis

5. **05_explainability.ipynb**: âœ… **COMPLETE**
   - SHAP implementation with TreeExplainer
   - Global feature importance analysis (BMI, exercise top predictors)
   - Clinical interpretation of optimization paradox
   - Root cause validation of deployment failures

3. **03_modeling.ipynb**: âœ… **COMPLETE**
   - 5 baseline algorithms implementation
   - Hyperparameter optimization 
   - Comprehensive performance evaluation

4. **04_error_analysis.ipynb**: âœ… **COMPLETE**
   - Systematic diagnostic assessment
   - Confusion matrix clinical analysis
   - Cross-model agreement and error pattern detection
   - Clinical cost-benefit evaluation

5. **05_explainability_tests.ipynb**: â³ **PLANNED**
   - SHAP and LIME implementation
   - Individual patient explanation validation
   - Clinical decision support framework

### Current Research Status (January 2026)

**Week 1-2 Completed Tasks:**
- âœ… Comprehensive EDA with clinical insights
- âœ… Professional data preprocessing pipeline
- âœ… Baseline modeling (5 algorithms: LR, RF, XGBoost, SVM, NN)
- âœ… Comprehensive error analysis and diagnostic evaluation
- âœ… Clinical metrics framework implementation
- âœ… Professional documentation and reporting

**Week 3-4 Completed Tasks:**
- âœ… **Hyperparameter Optimization**: RandomizedSearchCV framework with F1-score optimization
- âœ… **Early Validation Framework**: Test set validation revealing true performance hierarchy
- âœ… **Advanced Error Analysis**: Post-optimization clinical safety assessment
- âœ… **Literature Review**: 58-reference state-of-the-art analysis with XAI foundation
- âœ… **Documentation Updates**: Final report integration with Week 3-4 findings

**Phase 3 Planned Tasks:**
- â³ SHAP explainability implementation with clinical feature importance
- â³ LIME local interpretability for individual patient explanations
- â³ Clinical decision support template development
- â³ Deployment readiness assessment with safety validation

### Python Scripts - Production Pipeline

- **data_preprocessing.py**: âœ… Automated EDA and preprocessing pipeline
- **train_models.py**: âœ… Multi-model training with systematic evaluation
- **evaluate_models.py**: âœ… Comprehensive performance analysis framework
- **explainability.py**: â³ SHAP/LIME explanation generation
- **tuning/randomized_search.py**: âœ… Hyperparameter optimization framework
- **models/neural_network.py**: âœ… Neural network architecture with clinical optimization

### Configuration Management

Modify `src/config.yaml` to adjust:
- Model hyperparameters and training settings
- Data processing and feature engineering parameters
- Evaluation metrics and clinical thresholds
- Explanation generation and visualization settings
- Output directories and file organization

## Data Description

**European Social Survey Health Dataset**
- **Sample Size**: 2,682 patients with 16 clinical features
- **Target Variable**: Binary heart disease indicator (18.4% positive rate)
- **Data Quality**: Professional cleaning and validation pipeline implemented

**Feature Categories:**
- **Demographics**: Age, gender, country of residence
- **Lifestyle Factors**: Exercise frequency, diet quality, smoking status, alcohol consumption
- **Mental Health**: Happiness scale, depression indicators, stress levels
- **Medical History**: Diabetes status, blood pressure readings
- **Social Determinants**: Community engagement, environmental noise exposure

**Data Splits (Stratified)**:
- **Training Set**: 70% (1,877 samples)
- **Validation Set**: 15% (403 samples) 
- **Test Set**: 15% (402 samples)

## Research Methodology and Results

### Optimized Models Performance Summary

Based on comprehensive hyperparameter optimization and test set validation:

| Model | Test F1-Score | Sensitivity | Specificity | Clinical Assessment |
|-------|---------------|-------------|-------------|---------------------|
| **Adaptive_Ensemble** | **0.175** | 14.3% | 98.4% | **Best performance but clinically unsafe** |
| Optimal_Hybrid | 0.091 | 5.4% | 99.1% | Extremely conservative, misses 94.6% cases |
| Adaptive_LR | 0.032 | 1.8% | 99.4% | Nearly unusable for screening |

### Critical Research Findings (Post-Optimization)

1. **Clinical Safety Failure**: All optimized models fail to meet healthcare deployment criteria (required â‰¥80% sensitivity)
2. **Performance vs. Literature Gap**: Significant disparity between our optimized results (17.5% F1) and published benchmarks (65-92% F1)
3. **Systematic Model Limitations**: Consistent poor performance across all optimization attempts indicates fundamental prediction challenges
4. **Psychological Factor Insufficiency**: Mental health and lifestyle variables insufficient for clinical-grade heart disease prediction
5. **Economic Impact Analysis**: 822 missed heart disease cases per 8,476 patients represents unacceptable medical and economic risk

### Clinical Implications

- **False Positive Cost**: â‚¬100 (unnecessary testing/anxiety)
- **False Negative Cost**: â‚¬1000 (missed diagnosis/delayed treatment)
- **Optimal Threshold Strategy**: Balance sensitivity for life-critical screening applications
- **Clinical Decision Support**: Model explanations essential for healthcare professional adoption

## Explainable AI Framework

### XAI Techniques Implementation
- **SHAP (SHapley Additive exPlanations)**: 
  - Global feature importance analysis
  - Individual prediction explanations
  - Feature interaction detection
  - Clinical pathway visualization

- **LIME (Local Interpretable Model-agnostic Explanations)**:
  - Local instance explanations for individual patients
  - Feature perturbation analysis
  - Clinical decision boundary exploration
  - Healthcare professional interface design

### Clinical Decision Support Integration
- **Risk Factor Analysis**: Automated explanation templates for healthcare professionals
- **Patient Communication**: Interpretable risk factor explanations for patient education
- **Clinical Workflow**: Integration with existing healthcare information systems
- **Regulatory Compliance**: Explanation framework meeting medical AI transparency requirements

## Academic Documentation

This project maintains comprehensive documentation for academic research:

### Research Reports
- **[Final Report](reports/final_report.md)**: Comprehensive thesis with methodology, findings, and clinical implications
- **[Literature Review](reports/literature_review.md)**: Systematic survey of 58 peer-reviewed publications (2019-2026)
- **[Project Documentation](reports/)**: Progress reports and technical specifications

### Technical Implementation
- **Model Performance**: Comprehensive evaluation metrics and clinical safety analysis
- **Error Analysis**: Systematic diagnostic assessment with healthcare implications  
- **Reproducibility**: Complete environment specifications and Docker deployment
- **Code Quality**: Professional implementation standards

## Contributing and Collaboration

### Academic Research
1. Review methodology and findings in [reports/final_report.md](reports/final_report.md)
2. Examine implementation details in research notebooks
3. Propose improvements via GitHub issues with clinical context
4. Follow professional documentation standards

### Technical Development
- Fork repository for experimental features
- Create descriptive feature branches
- Maintain compatibility with clinical evaluation framework
- Submit pull requests with comprehensive testing

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- **European Social Survey** for comprehensive health dataset
- **SHAP and LIME teams** for explainability frameworks
- **Gradio development team** for healthcare application interface
- **PyTorch and Scikit-learn communities** for ML infrastructure
